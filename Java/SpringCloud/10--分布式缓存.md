# 分布式缓存

## 1. Redis

单点Redis的问题
* 数据丢失问题  ``实现Redis数据持久化``
* 并发能力问题  ``搭建主从集群，实现读写分离``
* 存储能力问题  ``搭建分片集群，利用插槽机制实现动态扩容``
* 故障恢复问题  ``利用Redis哨兵，实现健康检测和自动恢复``

### 1.1 Redis持久化

#### 1.1.1 RDB持久化

save ""

> redis-cli
> 
> bgsave # 开启子进程执行RDB，避免主进程受到影响

1. bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入RDB文件

2. fork采用的是copy-on-write技术：
* 当主进程执行读操作时，访问共享内存
* 当主进程执行写操作时，则会拷贝一份数据，执行写操作

3. 缺点
* RDB执行间隔时间长，两次RDB之间写入数据有丢失风险
* fork子进程、压缩、写出RDB文件都比较耗时

#### 1.1.2 AOF持久化(可以看做是命令日志文件)

因为是记录命令，AOF文件会比RDB文件大得多。而且AOF会记录对同一个key的多次写操作，但只有最后一次写操作才有意义。通过执行
``bgrewriteaof``命令，可以让AOF文件执行重写功能，用最少的命令达到相同效果

### 1.2 Redis主从

1. 搭建主从架构(实现读写分离)

2. 数据同步原理
* 主从第一次同步是*全量同步*，但如果slave重启后同步，则进行增量同步
> repl_baklog大小有上限，写满后会覆盖最早的数据。如果salve断开时间很久，导致尚未备份的数据被覆盖，则无法基于log做增量同步，只能再次全量同步

master如何判断slave是不是第一次来同步数据？
> Replication Id: 简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid
>
> offset: 偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master
的offset，说明slave数据落后于master，需要更新
>
> 因此slave做数据同步，必须向master声明自己的replication id和offset，master才可以判断到底需要同步哪些数据

3. 从以下方面来优化Redis主从就集群
* 在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO
* Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO
* 适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步
* 限制一个master上的slave节点数量，如果实在太多slave，则可以采用主-从-从链式结构，减少master压力


### 1.3 Redis哨兵

#### 1.3.1 哨兵的作用及原理
1. 哨兵的作用
* 监控
* 自动故障恢复  ``如果master故障，Sentinel会将一个slave提升为master。当故障恢复实例后也以新的master为主``
* 通知  ``Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送到Redis的客户端``

2. 服务状态监控

Sentinel基于心跳机制监测服务状态：
* 主观下线
* 客观下线

3. 选举新的master
* 首先会判断slave节点与master节点断开时间长短，如果超过指定值(down-after-milliseconds*10)则会排除该slave节点
* 然后判断slave节点的slave-priority值，越小优先级越高，如果是0则永不参与选举
* 如果slave-priority一样，则判断slave节点的offset值，越大说明数据越新，优先级越高
* 最后是判断slave节点的运行id大小，越小优先级越高

4. 实现故障转移
* 首先选定一个slave作为新的master，执行slaveof noone
* 然后让所有节点都执行slaveof 新master
* 修改故障节点配置，添加slaveof 新master

#### 1.3.2 搭建哨兵集群

#### 1.3.3 RedisTemplate的哨兵模式
Spring的RedisTemplate底层利用lettuce实现了节点的感知和自动切换

1. 在pom中引入redis的starter依赖
```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifaceId>spring-boot-starter-data-redis</artifaceId>
</dependency> 
```
2. 然后再配置文件中指定sentinel相关信息
```yaml
spring:
  redis:
    sentinel:
      master: mymaster # 指定master名称
        nodes: # 指定redis-sentinel集群信息
          - 192.168.150.101：27001
          - 192.168.150.101：27002
          - 192.168.150.101：27003
```
3. 配置主从读写分离
```java
@Bean
public lettuceClientConfigurationBuilderCustomizer configurationBuilderCustomizer(){
    return configBuilder -> configBuilder.readFrom(ReadFrom.REPLICA_PREFERRED);
        }
/**
 * 这里的ReadFrom是配置Redis的读取策略，是一个枚举，包括下面选择：
 * MASTER  从主节点读取
 * MASTER_PREFERRED  优先从master节点读取，master不可用才读取replica
 * REPLICA  从slave(replica)节点读取
 * REPLICA_PREFERRED  优先从slave(replica)节点读取，所有的slave都不可用才读取master
 */
```
### 1.4 Redis分片集群

1. 主从和哨兵可以解决高可用、高并发读的问题，但是依然有两个问题没有解决：
* 海量数据存储问题
* 高并发写的问题

2. 使用分片集群可以解决上述问题，分片集群特征：
* 集群中有多个master，每个master保存不同数据
* 每个master都可以有多个slave节点
* master之间通过ping监测彼此健康状态
* 客户端请求可以访问集群任意节点，最终都会被转发到正确节点

#### 1.4.1 搭建分片集群

#### 1.4.2 散列插槽

Redis会把每一个master节点映射到0-16383共16384个插槽(hash slot)上

1. 数据key不是与节点绑定，而是与插槽绑定。Redis根据key的有效部分计算插槽值，分两种情况：
* key中包含"{}"，且"{}"中至少包含一个字符，"{}"中的部分是有效部分
* key中不包含"{}"，整个key都是有效部分

2. Redis如何判断某个key应该在哪个实例
* 将15384个插槽分配到不同的实例
* 根据key的有效部分计算哈希值，对16384取余
* 余数作为插槽，寻找插槽所在实例即可

#### 1.4.3 集群伸缩

#### 1.4.4 故障转移
1. 自动故障转移
* 当集群中有一个master宕机首先是该实例与其他实例失去连接
* 然后是疑似宕机
* 最后是确定下线，自动提升一个slave为新的master

2. 手动故障转移
> cluster failover
* slave节点告诉master节点拒绝任何客户端连接
* master返回当前的数据offset给slave
* 等待数据offset与master一致
* 开始故障转移
* slave标记自己为master，广播故障转移的结果

#### 1.4.5 RedisTemplate访问分片集群
1. 引入redis的starter依赖
2. 配置分片集群地址
```yml
spring:
    redis:
      cluster:
        nodes:  # 指定分片集群的每一个节点信息
          - 192.168.150.101:7001
          - 192.168.150.101:7002
          - 192.168.150.101:7003
          - 192.168.150.101:8001
          - 192.168.150.101:8002
          - 192.168.150.101:8003
```
3. 配置读写分离
